{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c014a75-2ce9-41aa-beaa-aaf02ea2c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "image_size = 224\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64627180-90ed-4afe-a03e-80dd9464f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 7 * 7 * 256),\n",
    "            nn.BatchNorm1d(7 * 7 * 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Unflatten(1, (256, 7, 7)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a317d078-6ca4-4bd8-afcd-9cdb441099d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 14 * 14, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02483c70-fa36-4e5c-9025-f742bebe05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_data(generator, num_samples):\n",
    "    input_data = torch.randn(num_samples, latent_dim, device=device)\n",
    "    fake_images = generator(input_data)\n",
    "    return fake_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c015b0c-52b6-486b-86ae-38f411113717",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(r'C:\\GANproject\\dataset\\archive', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e56fc6-a48f-41b5-b6ac-6d219357eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def show_generated_images(fake_images, epoch):\n",
    "    fake_images = (fake_images + 1) / 2.0  # Rescale from [-1, 1] to [0, 1]\n",
    "    save_image(fake_images[:10], f'{epoch}_generated_images.png', nrow=5, normalize=True)'''\n",
    "def show_generated_images(fake_images, epoch, save_dir=r'C:\\GANproject\\Genimages'):\n",
    "    if not os.path.exists(r'C:\\GANproject\\Genimages'):\n",
    "        os.makedirs(r'C:\\GANproject\\Genimages')\n",
    "    fake_images = (fake_images + 1) / 2.0  # Rescale from [-1, 1] to [0, 1]\n",
    "    save_image(fake_images[:10], os.path.join(save_dir, f'{epoch}_generated_images.png'), nrow=5, normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67b61d1-cf32-446a-a3f1-346686b555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(generator, epoch):\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = f'generator_model_epoch_{epoch}_{now}.pth'\n",
    "    torch.save(generator.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ef9693-9463-4e15-95c0-9a4b3c988f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dataloader, optimizer_g, optimizer_d, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            current_batch_size = real_images.size(0)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            fake_images = create_fake_data(generator, current_batch_size)\n",
    "            real_labels = torch.ones(current_batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(current_batch_size, 1, device=device)\n",
    "\n",
    "            output_real = discriminator(real_images)\n",
    "            output_fake = discriminator(fake_images.detach())\n",
    "\n",
    "            loss_real = criterion(output_real, real_labels)\n",
    "            loss_fake = criterion(output_fake, fake_labels)\n",
    "\n",
    "            loss_d = loss_real + loss_fake\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_g.zero_grad()\n",
    "            output_fake = discriminator(fake_images)\n",
    "            loss_g = criterion(output_fake, real_labels)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] | Loss D: {loss_d.item()} | Loss G: {loss_g.item()}')\n",
    "            show_generated_images(fake_images, epoch)\n",
    "            save_model(generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bb0133-4b5d-44de-a00e-ca51a4407b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator is on: cuda:0\n",
      "Discriminator is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate models and optimizers\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Check if models are on GPU\n",
    "print(f\"Generator is on: {next(generator.parameters()).device}\")\n",
    "print(f\"Discriminator is on: {next(discriminator.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755900c1-3750-463e-99bd-f9c3e1b6b7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300] | Loss D: 0.667374849319458 | Loss G: 1.9894335269927979\n",
      "Model saved to generator_model_epoch_9_20240903_025734.pth\n",
      "Epoch [20/300] | Loss D: 1.6684943437576294 | Loss G: 0.5670934915542603\n",
      "Model saved to generator_model_epoch_19_20240903_033039.pth\n",
      "Epoch [30/300] | Loss D: 0.8166041374206543 | Loss G: 2.3505280017852783\n",
      "Model saved to generator_model_epoch_29_20240903_040344.pth\n",
      "Epoch [40/300] | Loss D: 0.5800735950469971 | Loss G: 2.043039321899414\n",
      "Model saved to generator_model_epoch_39_20240903_043648.pth\n",
      "Epoch [50/300] | Loss D: 0.5109657049179077 | Loss G: 2.3526721000671387\n",
      "Model saved to generator_model_epoch_49_20240903_050953.pth\n",
      "Epoch [60/300] | Loss D: 0.9265035390853882 | Loss G: 2.0039336681365967\n",
      "Model saved to generator_model_epoch_59_20240903_054258.pth\n",
      "Epoch [70/300] | Loss D: 0.4779430031776428 | Loss G: 2.7353222370147705\n",
      "Model saved to generator_model_epoch_69_20240903_061602.pth\n",
      "Epoch [80/300] | Loss D: 0.4511052668094635 | Loss G: 2.50262188911438\n",
      "Model saved to generator_model_epoch_79_20240903_064906.pth\n",
      "Epoch [90/300] | Loss D: 0.43462657928466797 | Loss G: 2.6686010360717773\n",
      "Model saved to generator_model_epoch_89_20240903_072211.pth\n",
      "Epoch [100/300] | Loss D: 0.5220031142234802 | Loss G: 2.3708438873291016\n",
      "Model saved to generator_model_epoch_99_20240903_075512.pth\n",
      "Epoch [110/300] | Loss D: 0.20806941390037537 | Loss G: 3.8962972164154053\n",
      "Model saved to generator_model_epoch_109_20240903_082816.pth\n",
      "Epoch [120/300] | Loss D: 0.3479953110218048 | Loss G: 3.299995183944702\n",
      "Model saved to generator_model_epoch_119_20240903_090123.pth\n",
      "Epoch [130/300] | Loss D: 0.3881012201309204 | Loss G: 3.3252322673797607\n",
      "Model saved to generator_model_epoch_129_20240903_093428.pth\n",
      "Epoch [140/300] | Loss D: 0.31469351053237915 | Loss G: 3.421420097351074\n",
      "Model saved to generator_model_epoch_139_20240903_100738.pth\n",
      "Epoch [150/300] | Loss D: 0.37118151783943176 | Loss G: 2.8445587158203125\n",
      "Model saved to generator_model_epoch_149_20240903_104046.pth\n",
      "Epoch [160/300] | Loss D: 0.2715930640697479 | Loss G: 3.482729196548462\n",
      "Model saved to generator_model_epoch_159_20240903_111352.pth\n",
      "Epoch [170/300] | Loss D: 0.21396929025650024 | Loss G: 3.4908666610717773\n",
      "Model saved to generator_model_epoch_169_20240903_114659.pth\n",
      "Epoch [180/300] | Loss D: 0.3643801510334015 | Loss G: 2.307521104812622\n",
      "Model saved to generator_model_epoch_179_20240903_122006.pth\n",
      "Epoch [190/300] | Loss D: 0.3787653148174286 | Loss G: 4.785677909851074\n",
      "Model saved to generator_model_epoch_189_20240903_125317.pth\n",
      "Epoch [200/300] | Loss D: 0.1928548365831375 | Loss G: 3.934818983078003\n",
      "Model saved to generator_model_epoch_199_20240903_132626.pth\n",
      "Epoch [210/300] | Loss D: 0.574440062046051 | Loss G: 1.2790342569351196\n",
      "Model saved to generator_model_epoch_209_20240903_135933.pth\n",
      "Epoch [220/300] | Loss D: 0.30533185601234436 | Loss G: 3.012939453125\n",
      "Model saved to generator_model_epoch_219_20240903_143240.pth\n",
      "Epoch [230/300] | Loss D: 0.30222225189208984 | Loss G: 3.171189785003662\n",
      "Model saved to generator_model_epoch_229_20240903_150550.pth\n",
      "Epoch [240/300] | Loss D: 0.35614505410194397 | Loss G: 2.5058209896087646\n",
      "Model saved to generator_model_epoch_239_20240903_153855.pth\n",
      "Epoch [250/300] | Loss D: 0.30058753490448 | Loss G: 5.748420715332031\n",
      "Model saved to generator_model_epoch_249_20240903_161200.pth\n",
      "Epoch [260/300] | Loss D: 0.2987765073776245 | Loss G: 3.2292685508728027\n",
      "Model saved to generator_model_epoch_259_20240903_164507.pth\n",
      "Epoch [270/300] | Loss D: 0.27322918176651 | Loss G: 3.502019166946411\n",
      "Model saved to generator_model_epoch_269_20240903_171816.pth\n",
      "Epoch [280/300] | Loss D: 0.16636332869529724 | Loss G: 3.3885207176208496\n",
      "Model saved to generator_model_epoch_279_20240903_175126.pth\n",
      "Epoch [290/300] | Loss D: 0.11062052845954895 | Loss G: 3.7169599533081055\n",
      "Model saved to generator_model_epoch_289_20240903_182434.pth\n",
      "Epoch [300/300] | Loss D: 0.34877365827560425 | Loss G: 2.7813074588775635\n",
      "Model saved to generator_model_epoch_299_20240903_185745.pth\n"
     ]
    }
   ],
   "source": [
    "# Instantiate models and optimizers\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the models\n",
    "train(generator, discriminator, dataloader, optimizer_g, optimizer_d, criterion, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
