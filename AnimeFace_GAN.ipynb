{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8217c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d580e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ceafe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 64\n",
    "nz = 100  # Size of latent vector\n",
    "ngf = 64  # Generator feature maps\n",
    "ndf = 64  # Discriminator feature maps\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_path = r\"C:\\Users\\krish\\Downloads\\archive (10)\\images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeFaceDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root, f) for f in os.listdir(root) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054ad2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = AnimeFaceDataset(root=dataset_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f2559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "generator = nn.Sequential(\n",
    "    nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "    nn.BatchNorm2d(ngf * 8),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ngf * 4),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ngf * 2),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ngf),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "    nn.Tanh()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b07470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "discriminator = nn.Sequential(\n",
    "    nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ndf * 2),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ndf * 4),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(ndf * 8),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "    nn.Sigmoid()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ab50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc4a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Step [0/497], LossD: 1.4251, LossG: 2.2791\n",
      "Epoch [0/50], Step [100/497], LossD: 0.4348, LossG: 3.5041\n",
      "Epoch [0/50], Step [200/497], LossD: 0.8391, LossG: 5.6006\n",
      "Epoch [0/50], Step [300/497], LossD: 0.6620, LossG: 6.5078\n",
      "Epoch [0/50], Step [400/497], LossD: 0.3409, LossG: 4.5688\n",
      "Epoch [1/50], Step [0/497], LossD: 0.2983, LossG: 5.4858\n",
      "Epoch [1/50], Step [100/497], LossD: 0.2084, LossG: 5.4767\n",
      "Epoch [1/50], Step [200/497], LossD: 0.5317, LossG: 3.2868\n",
      "Epoch [1/50], Step [300/497], LossD: 0.9731, LossG: 7.6769\n",
      "Epoch [1/50], Step [400/497], LossD: 0.3321, LossG: 6.2790\n",
      "Epoch [2/50], Step [0/497], LossD: 0.4118, LossG: 4.3672\n",
      "Epoch [2/50], Step [100/497], LossD: 0.3976, LossG: 6.9068\n",
      "Epoch [2/50], Step [200/497], LossD: 0.4400, LossG: 5.3785\n",
      "Epoch [2/50], Step [300/497], LossD: 0.7516, LossG: 7.7937\n",
      "Epoch [2/50], Step [400/497], LossD: 0.2633, LossG: 4.2789\n",
      "Epoch [3/50], Step [0/497], LossD: 0.0514, LossG: 5.0137\n",
      "Epoch [3/50], Step [100/497], LossD: 0.2407, LossG: 4.6424\n",
      "Epoch [3/50], Step [200/497], LossD: 1.8676, LossG: 14.6716\n",
      "Epoch [3/50], Step [300/497], LossD: 0.2429, LossG: 5.3434\n",
      "Epoch [3/50], Step [400/497], LossD: 0.1817, LossG: 4.9089\n",
      "Epoch [4/50], Step [0/497], LossD: 0.3709, LossG: 6.8014\n",
      "Epoch [4/50], Step [100/497], LossD: 0.7701, LossG: 12.3896\n",
      "Epoch [4/50], Step [200/497], LossD: 0.3098, LossG: 6.8707\n",
      "Epoch [4/50], Step [300/497], LossD: 0.1508, LossG: 5.7445\n",
      "Epoch [4/50], Step [400/497], LossD: 0.9576, LossG: 14.8178\n",
      "Epoch [5/50], Step [0/497], LossD: 0.1514, LossG: 5.3848\n",
      "Epoch [5/50], Step [100/497], LossD: 0.1597, LossG: 5.9610\n",
      "Epoch [5/50], Step [200/497], LossD: 0.2059, LossG: 5.2387\n",
      "Epoch [5/50], Step [300/497], LossD: 0.6628, LossG: 14.9524\n",
      "Epoch [5/50], Step [400/497], LossD: 0.1956, LossG: 4.5768\n",
      "Epoch [6/50], Step [0/497], LossD: 0.7568, LossG: 15.2005\n",
      "Epoch [6/50], Step [100/497], LossD: 0.1347, LossG: 5.2906\n",
      "Epoch [6/50], Step [200/497], LossD: 0.7865, LossG: 12.6857\n",
      "Epoch [6/50], Step [300/497], LossD: 0.2035, LossG: 6.7138\n",
      "Epoch [6/50], Step [400/497], LossD: 0.5597, LossG: 11.4274\n",
      "Epoch [7/50], Step [0/497], LossD: 0.0726, LossG: 4.4391\n",
      "Epoch [7/50], Step [100/497], LossD: 0.1814, LossG: 9.3535\n",
      "Epoch [7/50], Step [200/497], LossD: 0.1405, LossG: 7.5950\n",
      "Epoch [7/50], Step [300/497], LossD: 0.0826, LossG: 5.3313\n",
      "Epoch [7/50], Step [400/497], LossD: 0.4318, LossG: 12.9051\n",
      "Epoch [8/50], Step [0/497], LossD: 0.0968, LossG: 4.8717\n",
      "Epoch [8/50], Step [100/497], LossD: 0.3911, LossG: 10.3129\n",
      "Epoch [8/50], Step [200/497], LossD: 0.1251, LossG: 5.5898\n",
      "Epoch [8/50], Step [300/497], LossD: 0.1212, LossG: 11.5272\n",
      "Epoch [8/50], Step [400/497], LossD: 0.1763, LossG: 8.6519\n",
      "Epoch [9/50], Step [0/497], LossD: 0.1954, LossG: 9.3823\n",
      "Epoch [9/50], Step [100/497], LossD: 0.1486, LossG: 3.8263\n",
      "Epoch [9/50], Step [200/497], LossD: 0.0090, LossG: 10.8214\n",
      "Epoch [9/50], Step [300/497], LossD: 0.1458, LossG: 5.4334\n",
      "Epoch [9/50], Step [400/497], LossD: 0.2062, LossG: 8.2964\n",
      "Epoch [10/50], Step [0/497], LossD: 0.1217, LossG: 5.5528\n",
      "Epoch [10/50], Step [100/497], LossD: 0.1125, LossG: 6.7062\n",
      "Epoch [10/50], Step [200/497], LossD: 0.0775, LossG: 3.7100\n",
      "Epoch [10/50], Step [300/497], LossD: 0.1597, LossG: 4.9880\n",
      "Epoch [10/50], Step [400/497], LossD: 0.1242, LossG: 5.6640\n",
      "Epoch [11/50], Step [0/497], LossD: 0.1239, LossG: 5.9102\n",
      "Epoch [11/50], Step [100/497], LossD: 0.1984, LossG: 8.9284\n",
      "Epoch [11/50], Step [200/497], LossD: 0.2530, LossG: 4.1721\n",
      "Epoch [11/50], Step [300/497], LossD: 0.0420, LossG: 9.1697\n",
      "Epoch [11/50], Step [400/497], LossD: 0.0766, LossG: 5.6258\n",
      "Epoch [12/50], Step [0/497], LossD: 0.0979, LossG: 6.4768\n",
      "Epoch [12/50], Step [100/497], LossD: 0.2804, LossG: 10.4565\n",
      "Epoch [12/50], Step [200/497], LossD: 0.0961, LossG: 6.7029\n",
      "Epoch [12/50], Step [300/497], LossD: 0.0469, LossG: 2.1221\n",
      "Epoch [12/50], Step [400/497], LossD: 0.1466, LossG: 5.0588\n",
      "Epoch [13/50], Step [0/497], LossD: 0.0779, LossG: 5.1849\n",
      "Epoch [13/50], Step [100/497], LossD: 0.3129, LossG: 11.1931\n",
      "Epoch [13/50], Step [200/497], LossD: 0.7885, LossG: 17.0294\n",
      "Epoch [13/50], Step [300/497], LossD: 0.2499, LossG: 5.2904\n",
      "Epoch [13/50], Step [400/497], LossD: 2.2626, LossG: 7.5694\n",
      "Epoch [14/50], Step [0/497], LossD: 0.1262, LossG: 4.2613\n",
      "Epoch [14/50], Step [100/497], LossD: 0.0919, LossG: 5.1309\n",
      "Epoch [14/50], Step [200/497], LossD: 0.1714, LossG: 7.1274\n",
      "Epoch [14/50], Step [300/497], LossD: 0.0745, LossG: 4.4025\n",
      "Epoch [14/50], Step [400/497], LossD: 0.0797, LossG: 5.8149\n",
      "Epoch [15/50], Step [0/497], LossD: 0.1361, LossG: 5.2812\n",
      "Epoch [15/50], Step [100/497], LossD: 0.1196, LossG: 5.7687\n",
      "Epoch [15/50], Step [200/497], LossD: 0.1307, LossG: 5.6494\n",
      "Epoch [15/50], Step [300/497], LossD: 0.2140, LossG: 4.2598\n",
      "Epoch [15/50], Step [400/497], LossD: 0.2877, LossG: 6.4752\n",
      "Epoch [16/50], Step [0/497], LossD: 0.1779, LossG: 4.5281\n",
      "Epoch [16/50], Step [100/497], LossD: 0.0737, LossG: 6.0345\n",
      "Epoch [16/50], Step [200/497], LossD: 0.1394, LossG: 5.1248\n",
      "Epoch [16/50], Step [300/497], LossD: 0.1208, LossG: 5.7268\n",
      "Epoch [16/50], Step [400/497], LossD: 0.1993, LossG: 5.7521\n",
      "Epoch [17/50], Step [0/497], LossD: 0.2377, LossG: 4.6924\n",
      "Epoch [17/50], Step [100/497], LossD: 0.4053, LossG: 9.9589\n",
      "Epoch [17/50], Step [200/497], LossD: 0.1737, LossG: 4.1489\n",
      "Epoch [17/50], Step [300/497], LossD: 0.0631, LossG: 5.4701\n",
      "Epoch [17/50], Step [400/497], LossD: 0.1490, LossG: 6.3681\n",
      "Epoch [18/50], Step [0/497], LossD: 0.0096, LossG: 4.2313\n",
      "Epoch [18/50], Step [100/497], LossD: 0.1002, LossG: 4.9946\n",
      "Epoch [18/50], Step [200/497], LossD: 0.3295, LossG: 8.5179\n",
      "Epoch [18/50], Step [300/497], LossD: 0.0944, LossG: 5.2277\n",
      "Epoch [18/50], Step [400/497], LossD: 0.1114, LossG: 5.8368\n",
      "Epoch [19/50], Step [0/497], LossD: 0.1914, LossG: 7.4513\n",
      "Epoch [19/50], Step [100/497], LossD: 3.0519, LossG: 5.2823\n",
      "Epoch [19/50], Step [200/497], LossD: 1.0635, LossG: 11.9596\n",
      "Epoch [19/50], Step [300/497], LossD: 0.1027, LossG: 4.7709\n",
      "Epoch [19/50], Step [400/497], LossD: 0.0962, LossG: 4.7087\n",
      "Epoch [20/50], Step [0/497], LossD: 0.1505, LossG: 6.1126\n",
      "Epoch [20/50], Step [100/497], LossD: 0.1650, LossG: 5.7956\n",
      "Epoch [20/50], Step [200/497], LossD: 0.1280, LossG: 5.2624\n",
      "Epoch [20/50], Step [300/497], LossD: 0.0946, LossG: 4.4744\n",
      "Epoch [20/50], Step [400/497], LossD: 0.1988, LossG: 4.3289\n",
      "Epoch [21/50], Step [0/497], LossD: 0.1026, LossG: 4.8572\n",
      "Epoch [21/50], Step [100/497], LossD: 0.1794, LossG: 4.0161\n",
      "Epoch [21/50], Step [200/497], LossD: 0.1422, LossG: 4.3859\n",
      "Epoch [21/50], Step [300/497], LossD: 1.0331, LossG: 7.9257\n",
      "Epoch [21/50], Step [400/497], LossD: 0.1398, LossG: 4.5411\n",
      "Epoch [22/50], Step [0/497], LossD: 0.1788, LossG: 4.0927\n",
      "Epoch [22/50], Step [100/497], LossD: 0.0739, LossG: 4.7075\n",
      "Epoch [22/50], Step [200/497], LossD: 0.1745, LossG: 4.1144\n",
      "Epoch [22/50], Step [300/497], LossD: 0.1227, LossG: 6.1973\n",
      "Epoch [22/50], Step [400/497], LossD: 0.1964, LossG: 6.2787\n",
      "Epoch [23/50], Step [0/497], LossD: 0.1377, LossG: 5.6091\n",
      "Epoch [23/50], Step [100/497], LossD: 0.1456, LossG: 3.8849\n",
      "Epoch [23/50], Step [200/497], LossD: 0.1458, LossG: 4.1646\n",
      "Epoch [23/50], Step [300/497], LossD: 0.0665, LossG: 4.5855\n",
      "Epoch [23/50], Step [400/497], LossD: 6.3452, LossG: 3.3297\n",
      "Epoch [24/50], Step [0/497], LossD: 0.1289, LossG: 5.1075\n",
      "Epoch [24/50], Step [100/497], LossD: 0.1331, LossG: 3.8027\n",
      "Epoch [24/50], Step [200/497], LossD: 0.1002, LossG: 5.2445\n",
      "Epoch [24/50], Step [300/497], LossD: 0.0651, LossG: 5.2367\n",
      "Epoch [24/50], Step [400/497], LossD: 0.0925, LossG: 4.7223\n",
      "Epoch [25/50], Step [0/497], LossD: 0.0763, LossG: 4.7451\n",
      "Epoch [25/50], Step [100/497], LossD: 0.0786, LossG: 5.8095\n",
      "Epoch [25/50], Step [200/497], LossD: 0.0715, LossG: 4.4500\n",
      "Epoch [25/50], Step [300/497], LossD: 0.2237, LossG: 6.6043\n",
      "Epoch [25/50], Step [400/497], LossD: 0.1002, LossG: 4.0469\n",
      "Epoch [26/50], Step [0/497], LossD: 0.5644, LossG: 3.5343\n",
      "Epoch [26/50], Step [100/497], LossD: 0.2897, LossG: 8.1596\n",
      "Epoch [26/50], Step [200/497], LossD: 0.1096, LossG: 4.2946\n",
      "Epoch [26/50], Step [300/497], LossD: 0.1121, LossG: 4.2232\n",
      "Epoch [26/50], Step [400/497], LossD: 0.2730, LossG: 5.5934\n",
      "Epoch [27/50], Step [0/497], LossD: 0.1520, LossG: 3.7882\n",
      "Epoch [27/50], Step [100/497], LossD: 0.0628, LossG: 4.7878\n",
      "Epoch [27/50], Step [200/497], LossD: 0.1471, LossG: 4.1368\n",
      "Epoch [27/50], Step [300/497], LossD: 0.1270, LossG: 5.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [400/497], LossD: 0.1508, LossG: 4.3178\n",
      "Epoch [28/50], Step [0/497], LossD: 0.0408, LossG: 5.4147\n",
      "Epoch [28/50], Step [100/497], LossD: 0.1087, LossG: 4.3643\n",
      "Epoch [28/50], Step [200/497], LossD: 0.7451, LossG: 1.8126\n",
      "Epoch [28/50], Step [300/497], LossD: 0.1204, LossG: 4.1689\n",
      "Epoch [28/50], Step [400/497], LossD: 0.0867, LossG: 4.8186\n",
      "Epoch [29/50], Step [0/497], LossD: 0.1034, LossG: 5.0871\n",
      "Epoch [29/50], Step [100/497], LossD: 0.0806, LossG: 5.8134\n",
      "Epoch [29/50], Step [200/497], LossD: 0.5582, LossG: 12.8214\n",
      "Epoch [29/50], Step [300/497], LossD: 0.0821, LossG: 4.5491\n",
      "Epoch [29/50], Step [400/497], LossD: 0.3104, LossG: 5.5814\n",
      "Epoch [30/50], Step [0/497], LossD: 0.0853, LossG: 4.5361\n",
      "Epoch [30/50], Step [100/497], LossD: 0.1033, LossG: 3.4002\n",
      "Epoch [30/50], Step [200/497], LossD: 0.1205, LossG: 3.6018\n",
      "Epoch [30/50], Step [300/497], LossD: 0.0954, LossG: 5.0119\n",
      "Epoch [30/50], Step [400/497], LossD: 0.0653, LossG: 4.7867\n",
      "Epoch [31/50], Step [0/497], LossD: 0.2196, LossG: 6.3158\n",
      "Epoch [31/50], Step [100/497], LossD: 0.1408, LossG: 3.2276\n",
      "Epoch [31/50], Step [200/497], LossD: 0.0861, LossG: 4.8627\n",
      "Epoch [31/50], Step [300/497], LossD: 0.0979, LossG: 4.6863\n",
      "Epoch [31/50], Step [400/497], LossD: 0.0777, LossG: 5.3873\n",
      "Epoch [32/50], Step [0/497], LossD: 2.2068, LossG: 0.3927\n",
      "Epoch [32/50], Step [100/497], LossD: 3.9819, LossG: 12.4098\n",
      "Epoch [32/50], Step [200/497], LossD: 0.1306, LossG: 5.7371\n",
      "Epoch [32/50], Step [300/497], LossD: 0.0959, LossG: 5.8287\n",
      "Epoch [32/50], Step [400/497], LossD: 0.1120, LossG: 4.1141\n",
      "Epoch [33/50], Step [0/497], LossD: 0.0649, LossG: 7.1784\n",
      "Epoch [33/50], Step [100/497], LossD: 2.1805, LossG: 18.4014\n",
      "Epoch [33/50], Step [200/497], LossD: 0.3560, LossG: 4.7959\n",
      "Epoch [33/50], Step [300/497], LossD: 0.1153, LossG: 4.0921\n",
      "Epoch [33/50], Step [400/497], LossD: 0.0957, LossG: 3.6239\n",
      "Epoch [34/50], Step [0/497], LossD: 0.4150, LossG: 3.9177\n",
      "Epoch [34/50], Step [100/497], LossD: 0.0903, LossG: 4.5965\n",
      "Epoch [34/50], Step [200/497], LossD: 5.8774, LossG: 0.6873\n",
      "Epoch [34/50], Step [300/497], LossD: 0.3717, LossG: 2.7202\n",
      "Epoch [34/50], Step [400/497], LossD: 0.0972, LossG: 4.2951\n",
      "Epoch [35/50], Step [0/497], LossD: 0.1128, LossG: 4.4367\n",
      "Epoch [35/50], Step [100/497], LossD: 0.1420, LossG: 5.8315\n",
      "Epoch [35/50], Step [200/497], LossD: 0.0657, LossG: 5.0154\n",
      "Epoch [35/50], Step [300/497], LossD: 0.0667, LossG: 4.3771\n",
      "Epoch [35/50], Step [400/497], LossD: 0.0816, LossG: 5.7560\n",
      "Epoch [36/50], Step [0/497], LossD: 0.6356, LossG: 3.9457\n",
      "Epoch [36/50], Step [100/497], LossD: 0.3596, LossG: 2.9092\n",
      "Epoch [36/50], Step [200/497], LossD: 0.1343, LossG: 4.4077\n",
      "Epoch [36/50], Step [300/497], LossD: 0.0860, LossG: 5.1240\n",
      "Epoch [36/50], Step [400/497], LossD: 2.6511, LossG: 13.0415\n",
      "Epoch [37/50], Step [0/497], LossD: 0.5589, LossG: 1.5945\n",
      "Epoch [37/50], Step [100/497], LossD: 0.1195, LossG: 4.7991\n",
      "Epoch [37/50], Step [200/497], LossD: 0.3070, LossG: 7.5044\n",
      "Epoch [37/50], Step [300/497], LossD: 0.1389, LossG: 4.8971\n",
      "Epoch [37/50], Step [400/497], LossD: 0.0779, LossG: 3.7638\n",
      "Epoch [38/50], Step [0/497], LossD: 0.1677, LossG: 6.5742\n",
      "Epoch [38/50], Step [100/497], LossD: 0.1748, LossG: 3.2907\n",
      "Epoch [38/50], Step [200/497], LossD: 0.2495, LossG: 4.7703\n",
      "Epoch [38/50], Step [300/497], LossD: 0.0878, LossG: 4.6604\n",
      "Epoch [38/50], Step [400/497], LossD: 0.0639, LossG: 4.3773\n",
      "Epoch [39/50], Step [0/497], LossD: 0.1316, LossG: 5.7542\n",
      "Epoch [39/50], Step [100/497], LossD: 0.0837, LossG: 3.9195\n",
      "Epoch [39/50], Step [200/497], LossD: 0.1770, LossG: 3.4596\n",
      "Epoch [39/50], Step [300/497], LossD: 0.0593, LossG: 4.6789\n",
      "Epoch [39/50], Step [400/497], LossD: 0.0595, LossG: 4.7915\n",
      "Epoch [40/50], Step [0/497], LossD: 0.1318, LossG: 6.4553\n",
      "Epoch [40/50], Step [100/497], LossD: 0.0664, LossG: 4.6402\n",
      "Epoch [40/50], Step [200/497], LossD: 0.0511, LossG: 5.2858\n",
      "Epoch [40/50], Step [300/497], LossD: 3.2411, LossG: 0.2877\n",
      "Epoch [40/50], Step [400/497], LossD: 0.2267, LossG: 7.7271\n",
      "Epoch [41/50], Step [0/497], LossD: 0.1061, LossG: 4.0909\n",
      "Epoch [41/50], Step [100/497], LossD: 0.2644, LossG: 7.4838\n",
      "Epoch [41/50], Step [200/497], LossD: 0.9270, LossG: 6.6245\n",
      "Epoch [41/50], Step [300/497], LossD: 0.1493, LossG: 5.6876\n",
      "Epoch [41/50], Step [400/497], LossD: 0.0472, LossG: 4.7387\n",
      "Epoch [42/50], Step [0/497], LossD: 0.0695, LossG: 5.5979\n",
      "Epoch [42/50], Step [100/497], LossD: 0.0430, LossG: 4.9025\n",
      "Epoch [42/50], Step [200/497], LossD: 0.1662, LossG: 3.7416\n",
      "Epoch [42/50], Step [300/497], LossD: 0.4104, LossG: 5.0898\n",
      "Epoch [42/50], Step [400/497], LossD: 0.1005, LossG: 5.0502\n",
      "Epoch [43/50], Step [0/497], LossD: 0.2604, LossG: 8.4741\n",
      "Epoch [43/50], Step [100/497], LossD: 0.0764, LossG: 3.9942\n",
      "Epoch [43/50], Step [200/497], LossD: 0.1369, LossG: 3.1583\n",
      "Epoch [43/50], Step [300/497], LossD: 0.2789, LossG: 2.8841\n",
      "Epoch [43/50], Step [400/497], LossD: 0.1224, LossG: 6.9185\n",
      "Epoch [44/50], Step [0/497], LossD: 0.1013, LossG: 4.8140\n",
      "Epoch [44/50], Step [100/497], LossD: 0.0766, LossG: 5.3277\n",
      "Epoch [44/50], Step [200/497], LossD: 0.0540, LossG: 5.7400\n",
      "Epoch [44/50], Step [300/497], LossD: 0.0507, LossG: 5.1231\n",
      "Epoch [44/50], Step [400/497], LossD: 4.9654, LossG: 3.7307\n",
      "Epoch [45/50], Step [0/497], LossD: 0.0595, LossG: 5.0726\n",
      "Epoch [45/50], Step [100/497], LossD: 0.1760, LossG: 5.1407\n",
      "Epoch [45/50], Step [200/497], LossD: 0.1400, LossG: 5.2710\n",
      "Epoch [45/50], Step [300/497], LossD: 0.3132, LossG: 5.8364\n",
      "Epoch [45/50], Step [400/497], LossD: 0.2004, LossG: 4.5714\n",
      "Epoch [46/50], Step [0/497], LossD: 0.0453, LossG: 4.5972\n",
      "Epoch [46/50], Step [100/497], LossD: 0.0411, LossG: 4.4378\n",
      "Epoch [46/50], Step [200/497], LossD: 0.0626, LossG: 5.0182\n",
      "Epoch [46/50], Step [300/497], LossD: 0.0916, LossG: 6.0692\n",
      "Epoch [46/50], Step [400/497], LossD: 0.4948, LossG: 6.2034\n",
      "Epoch [47/50], Step [0/497], LossD: 0.0502, LossG: 5.6604\n",
      "Epoch [47/50], Step [100/497], LossD: 0.0888, LossG: 5.1791\n",
      "Epoch [47/50], Step [200/497], LossD: 0.0540, LossG: 5.2220\n",
      "Epoch [47/50], Step [300/497], LossD: 0.1239, LossG: 3.7369\n",
      "Epoch [47/50], Step [400/497], LossD: 0.1222, LossG: 6.2025\n",
      "Epoch [48/50], Step [0/497], LossD: 0.0406, LossG: 5.2497\n",
      "Epoch [48/50], Step [100/497], LossD: 0.1760, LossG: 4.5220\n",
      "Epoch [48/50], Step [200/497], LossD: 0.1203, LossG: 5.2049\n",
      "Epoch [48/50], Step [300/497], LossD: 0.0594, LossG: 4.2776\n",
      "Epoch [48/50], Step [400/497], LossD: 0.1407, LossG: 4.8635\n",
      "Epoch [49/50], Step [0/497], LossD: 0.0602, LossG: 4.4264\n",
      "Epoch [49/50], Step [100/497], LossD: 0.1238, LossG: 5.1737\n",
      "Epoch [49/50], Step [200/497], LossD: 1.2328, LossG: 2.9410\n",
      "Epoch [49/50], Step [300/497], LossD: 0.0712, LossG: 4.5145\n",
      "Epoch [49/50], Step [400/497], LossD: 0.0707, LossG: 5.1196\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for i, real_images in enumerate(dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizerD.zero_grad()\n",
    "        labels_real = torch.ones(batch_size, device=device)\n",
    "        labels_fake = torch.zeros(batch_size, device=device)\n",
    "        \n",
    "        output_real = discriminator(real_images).view(-1)\n",
    "        loss_real = criterion(output_real, labels_real)\n",
    "        \n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        output_fake = discriminator(fake_images.detach()).view(-1)\n",
    "        loss_fake = criterion(output_fake, labels_fake)\n",
    "        \n",
    "        lossD = loss_real + loss_fake\n",
    "        lossD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizerG.zero_grad()\n",
    "        output_fake = discriminator(fake_images).view(-1)\n",
    "        lossG = criterion(output_fake, labels_real)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], LossD: {lossD.item():.4f}, LossG: {lossG.item():.4f}')\n",
    "    \n",
    "    # Save generated images\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    vutils.save_image(fake_images, f\"{output_dir}/fake_samples_epoch_{epoch}.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80098ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(generator.state_dict(), 'AnimeFace_generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'AnimeFace_discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0ec5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 generated.\n",
      "Sample 1 generated.\n",
      "Sample 2 generated.\n",
      "Sample 3 generated.\n",
      "Sample 4 generated.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    noise = torch.randn(16, nz, 1, 1, device=device)\n",
    "    samples = generator(noise)\n",
    "    vutils.save_image(samples, f\"{output_dir}/sample_{_}.png\", normalize=True)\n",
    "    print(f'Sample {_} generated.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (PyTorch)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
