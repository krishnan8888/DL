{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b111bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a27956",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'C:\\Users\\krish\\Downloads\\archive (3)\\traffic_Data'\n",
    "''' NOTE: I put all the test data all in subdirectories just like how DATA folder is structured , also a bunch of classes had no values in TEST so i copied some over from DATA'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dbf8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path, subset):\n",
    "    return image_dataset_from_directory(\n",
    "        os.path.join(dataset_path, subset),\n",
    "        image_size=(32, 32),\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2556587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4174 files belonging to 58 classes.\n",
      "Found 2009 files belonging to 58 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "OGtrain_dataset = load_dataset(dataset_path, \"DATA\")\n",
    "test_dataset = load_dataset(dataset_path, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78c51f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25), \n",
    "    layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25), \n",
    "    layers.Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.15), \n",
    "    layers.Dense(58, activation='softmax')  # Adjusted for 58 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2792dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ecf4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a0ac919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train dataset into train and validation\n",
    "# Take 20% of the train dataset as validation\n",
    "val_size = int(0.2 * len(OGtrain_dataset))  # 20% for validation\n",
    "train_size = len(OGtrain_dataset) - val_size\n",
    "\n",
    "# Shuffle the train dataset and split into train and validation\n",
    "train_dataset = OGtrain_dataset.take(train_size)  # Training dataset\n",
    "val_dataset = OGtrain_dataset.skip(train_size)  # Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "557112f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 6s 45ms/step - loss: 5.4987 - accuracy: 0.2101 - val_loss: 2.6691 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 2.2146 - accuracy: 0.5065 - val_loss: 1.5084 - val_accuracy: 0.7273 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 1.4901 - accuracy: 0.6875 - val_loss: 1.1334 - val_accuracy: 0.7899 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 1.1546 - accuracy: 0.7720 - val_loss: 0.8698 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.8953 - accuracy: 0.8363 - val_loss: 0.7092 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.7651 - accuracy: 0.8726 - val_loss: 0.6600 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.6776 - accuracy: 0.8991 - val_loss: 0.5074 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.6016 - accuracy: 0.9223 - val_loss: 0.4719 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.6006 - accuracy: 0.9232 - val_loss: 0.4926 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.5419 - accuracy: 0.9366 - val_loss: 0.4904 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.4880 - accuracy: 0.9565 - val_loss: 0.4110 - val_accuracy: 0.9791 - lr: 9.0484e-04\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.4533 - accuracy: 0.9631 - val_loss: 0.4087 - val_accuracy: 0.9828 - lr: 8.1873e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.4383 - accuracy: 0.9688 - val_loss: 0.4165 - val_accuracy: 0.9779 - lr: 7.4082e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.4160 - accuracy: 0.9705 - val_loss: 0.4065 - val_accuracy: 0.9853 - lr: 6.7032e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.4082 - accuracy: 0.9711 - val_loss: 0.3957 - val_accuracy: 0.9914 - lr: 6.0653e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3885 - accuracy: 0.9795 - val_loss: 0.3695 - val_accuracy: 0.9877 - lr: 5.4881e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3748 - accuracy: 0.9821 - val_loss: 0.3467 - val_accuracy: 0.9877 - lr: 4.9659e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3596 - accuracy: 0.9836 - val_loss: 0.3314 - val_accuracy: 0.9951 - lr: 4.4933e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3459 - accuracy: 0.9851 - val_loss: 0.3248 - val_accuracy: 0.9951 - lr: 4.0657e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.3353 - accuracy: 0.9887 - val_loss: 0.3356 - val_accuracy: 0.9914 - lr: 3.6788e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.3214 - accuracy: 0.9896 - val_loss: 0.3179 - val_accuracy: 0.9951 - lr: 3.3287e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3301 - accuracy: 0.9887 - val_loss: 0.3159 - val_accuracy: 0.9951 - lr: 3.0119e-04\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3190 - accuracy: 0.9920 - val_loss: 0.3139 - val_accuracy: 0.9951 - lr: 2.7253e-04\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3122 - accuracy: 0.9920 - val_loss: 0.3122 - val_accuracy: 0.9951 - lr: 2.4660e-04\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3060 - accuracy: 0.9917 - val_loss: 0.3061 - val_accuracy: 0.9951 - lr: 2.2313e-04\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.3029 - accuracy: 0.9932 - val_loss: 0.3106 - val_accuracy: 0.9926 - lr: 2.0190e-04\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2935 - accuracy: 0.9943 - val_loss: 0.3144 - val_accuracy: 0.9926 - lr: 1.8268e-04\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2924 - accuracy: 0.9946 - val_loss: 0.3162 - val_accuracy: 0.9951 - lr: 1.6530e-04\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2926 - accuracy: 0.9940 - val_loss: 0.3037 - val_accuracy: 0.9939 - lr: 1.4957e-04\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2902 - accuracy: 0.9935 - val_loss: 0.3088 - val_accuracy: 0.9926 - lr: 1.3534e-04\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2871 - accuracy: 0.9949 - val_loss: 0.2948 - val_accuracy: 0.9951 - lr: 1.2246e-04\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 4s 42ms/step - loss: 0.2810 - accuracy: 0.9961 - val_loss: 0.2871 - val_accuracy: 0.9926 - lr: 1.1080e-04\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2835 - accuracy: 0.9943 - val_loss: 0.2948 - val_accuracy: 0.9926 - lr: 1.0026e-04\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2831 - accuracy: 0.9917 - val_loss: 0.2931 - val_accuracy: 0.9926 - lr: 9.0718e-05\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2762 - accuracy: 0.9955 - val_loss: 0.2946 - val_accuracy: 0.9926 - lr: 8.2085e-05\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2820 - accuracy: 0.9943 - val_loss: 0.2927 - val_accuracy: 0.9926 - lr: 7.4274e-05\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2708 - accuracy: 0.9958 - val_loss: 0.2866 - val_accuracy: 0.9926 - lr: 6.7206e-05\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2730 - accuracy: 0.9958 - val_loss: 0.2820 - val_accuracy: 0.9951 - lr: 6.0810e-05\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2681 - accuracy: 0.9970 - val_loss: 0.2832 - val_accuracy: 0.9926 - lr: 5.5023e-05\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 5s 44ms/step - loss: 0.2696 - accuracy: 0.9958 - val_loss: 0.2799 - val_accuracy: 0.9926 - lr: 4.9787e-05\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2660 - accuracy: 0.9970 - val_loss: 0.2775 - val_accuracy: 0.9926 - lr: 4.5049e-05\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2641 - accuracy: 0.9967 - val_loss: 0.2809 - val_accuracy: 0.9926 - lr: 4.0762e-05\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2653 - accuracy: 0.9955 - val_loss: 0.2828 - val_accuracy: 0.9926 - lr: 3.6883e-05\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2612 - accuracy: 0.9970 - val_loss: 0.2831 - val_accuracy: 0.9926 - lr: 3.3373e-05\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2649 - accuracy: 0.9958 - val_loss: 0.2820 - val_accuracy: 0.9926 - lr: 3.0197e-05\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2581 - accuracy: 0.9976 - val_loss: 0.2778 - val_accuracy: 0.9926 - lr: 2.7324e-05\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2592 - accuracy: 0.9970 - val_loss: 0.2746 - val_accuracy: 0.9951 - lr: 2.4724e-05\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2582 - accuracy: 0.9970 - val_loss: 0.2757 - val_accuracy: 0.9926 - lr: 2.2371e-05\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 5s 43ms/step - loss: 0.2592 - accuracy: 0.9973 - val_loss: 0.2749 - val_accuracy: 0.9926 - lr: 2.0242e-05\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 5s 42ms/step - loss: 0.2543 - accuracy: 0.9982 - val_loss: 0.2752 - val_accuracy: 0.9926 - lr: 1.8316e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2167c5fd9d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)  # Exponentially decay the learning rate after epoch 10\n",
    "    \n",
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset, callbacks=[early_stopping, LearningRateScheduler(lr_scheduler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ab4cffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7908 - accuracy: 0.7203\n",
      "Test Accuracy: 0.7203\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9764e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters_and_pools(model, image):\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name or 'pool' in layer.name]\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    activations = activation_model.predict(image.reshape(1, 32, 32, 3))\n",
    "    \n",
    "    for i, activation in enumerate(activations):\n",
    "        num_filters = activation.shape[-1]\n",
    "        size = activation.shape[1]\n",
    "        fig, axes = plt.subplots(1, min(num_filters, 6), figsize=(15, 5))\n",
    "        for j in range(min(num_filters, 6)):\n",
    "            ax = axes[j]\n",
    "            ax.imshow(activation[0, :, :, j], cmap='viridis')\n",
    "            ax.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
